{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n-cls.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "num_epochs = 20\n",
    "image_size = 512\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.208 🚀 Python-3.11.5 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24252MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/home/pepe/dev/upb/topics/cats, epochs=20, patience=50, batch=256, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train12, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train12\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/pepe/dev/upb/topics/cats/train... found 2339 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/pepe/dev/upb/topics/cats/val... found 50 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/pepe/dev/upb/topics/cats/test... found 50 images in 10 classes ✅ \n",
      "Overriding model.yaml nc=1000 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n",
      "YOLOv8n-cls summary: 99 layers, 1451098 parameters, 1451098 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train12', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/pepe/dev/upb/topics/cats/train... 2339 images, 0 corrupt: 100%|██████████| 2339/2339 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/pepe/dev/upb/topics/cats/val... 50 images, 0 corrupt: 100%|██████████| 50/50 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.002), 27 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train12\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       1/20      23.1G      8.517         35        512: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s]\n",
      "                   all       0.18       0.52\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       2/20        23G      7.707         35        512: 100%|██████████| 10/10 [00:20<00:00,  2.09s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 57.07it/s]\n",
      "                   all       0.34       0.88\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       3/20        23G      6.138         35        512: 100%|██████████| 10/10 [00:03<00:00,  2.91it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 54.16it/s]\n",
      "                   all       0.52       0.98\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       4/20        23G       4.06         35        512: 100%|██████████| 10/10 [00:03<00:00,  3.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 57.10it/s]\n",
      "                   all       0.76          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       5/20        23G      2.452         35        512: 100%|██████████| 10/10 [00:03<00:00,  3.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 56.34it/s]\n",
      "                   all        0.8          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       6/20        23G      1.533         35        512: 100%|██████████| 10/10 [00:02<00:00,  3.42it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 58.03it/s]\n",
      "                   all       0.84          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       7/20        23G     0.9505         35        512: 100%|██████████| 10/10 [00:02<00:00,  3.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 57.90it/s]\n",
      "                   all       0.86          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       8/20        23G     0.5733         35        512: 100%|██████████| 10/10 [00:02<00:00,  3.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 54.68it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       9/20        23G     0.3523         35        512: 100%|██████████| 10/10 [00:02<00:00,  3.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 53.33it/s]\n",
      "                   all        0.9          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      10/20        23G     0.2012         35        512: 100%|██████████| 10/10 [00:02<00:00,  3.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 52.30it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      11/20      22.4G     0.1215         35        512: 100%|██████████| 10/10 [00:07<00:00,  1.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 51.63it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      12/20        23G     0.0749         35        512: 100%|██████████| 10/10 [00:02<00:00,  4.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 51.52it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      13/20        23G     0.0521         35        512: 100%|██████████| 10/10 [00:02<00:00,  4.25it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 51.21it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      14/20        23G    0.03754         35        512: 100%|██████████| 10/10 [00:02<00:00,  4.22it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 52.41it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      15/20        23G    0.02731         35        512: 100%|██████████| 10/10 [00:03<00:00,  3.25it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 55.27it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      16/20        23G    0.02289         35        512: 100%|██████████| 10/10 [00:03<00:00,  3.24it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 56.81it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      17/20        23G    0.02203         35        512: 100%|██████████| 10/10 [00:02<00:00,  3.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 55.40it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      18/20        23G    0.01855         35        512: 100%|██████████| 10/10 [00:02<00:00,  3.77it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 57.09it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      19/20        23G    0.01831         35        512: 100%|██████████| 10/10 [00:02<00:00,  3.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 54.45it/s]\n",
      "                   all       0.96          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      20/20        23G    0.01614         35        512: 100%|██████████| 10/10 [00:02<00:00,  3.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 53.63it/s]\n",
      "                   all       0.94          1\n",
      "\n",
      "20 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from runs/classify/train12/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from runs/classify/train12/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating runs/classify/train12/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 🚀 Python-3.11.5 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24252MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1447690 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/pepe/dev/upb/topics/cats/train... found 2339 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/pepe/dev/upb/topics/cats/val... found 50 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/pepe/dev/upb/topics/cats/test... found 50 images in 10 classes ✅ \n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s]\n",
      "                   all       0.96          1\n",
      "Speed: 1.5ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train12\u001b[0m\n",
      "Results saved to \u001b[1mruns/classify/train12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=\"/home/pepe/dev/upb/topics/cats\", epochs=num_epochs, imgsz=image_size, batch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.208 🚀 Python-3.11.5 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24252MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1447690 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/pepe/dev/upb/topics/cats/train... found 2339 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/pepe/dev/upb/topics/cats/val... found 50 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/pepe/dev/upb/topics/cats/test... found 50 images in 10 classes ✅ \n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/pepe/dev/upb/topics/cats/val... 50 images, 0 corrupt: 100%|██████████| 50/50 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all       0.96          1\n",
      "Speed: 0.1ms preprocess, 18.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train122\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fe21bd7e990>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9799999892711639\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9599999785423279, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9799999892711639}\n",
       "save_dir: PosixPath('runs/classify/train122')\n",
       "speed: {'preprocess': 0.1425933837890625, 'inference': 18.903603553771973, 'loss': 0.0002574920654296875, 'postprocess': 0.000247955322265625}\n",
       "task: 'classify'\n",
       "top1: 0.9599999785423279\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runs/classify/train12/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x512 CHEETAH 1.00, AFRICAN LEOPARD 0.00, LIONS 0.00, SNOW LEOPARD 0.00, CARACAL 0.00, 1: 512x512 CHEETAH 1.00, AFRICAN LEOPARD 0.00, OCELOT 0.00, LIONS 0.00, SNOW LEOPARD 0.00, 2: 512x512 PUMA 0.88, CARACAL 0.03, AFRICAN LEOPARD 0.02, OCELOT 0.02, CHEETAH 0.02, 3: 512x512 PUMA 0.94, LIONS 0.04, AFRICAN LEOPARD 0.00, TIGER 0.00, SNOW LEOPARD 0.00, 4: 512x512 TIGER 0.98, JAGUAR 0.01, AFRICAN LEOPARD 0.00, OCELOT 0.00, LIONS 0.00, 44.1ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]prediction: CHEETAH \t confidence: 0.9996352195739746\n",
      "\n",
      "\n",
      "[1]prediction: CHEETAH \t confidence: 0.9984240531921387\n",
      "\n",
      "\n",
      "[2]prediction: PUMA \t confidence: 0.8844305276870728\n",
      "\n",
      "\n",
      "[3]prediction: PUMA \t confidence: 0.9447306394577026\n",
      "\n",
      "\n",
      "[4]prediction: TIGER \t confidence: 0.9800947904586792\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = model([\"cheetah1.jpeg\", \"cheetah2.jpeg\", \"puma1.jpeg\", \"puma2.jpg\", \"tiger1.jpg\"])\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"[{i}]prediction: {res.names[res.probs.top1]} \\t confidence: {res.probs.data[res.probs.top1]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.208 🚀 Python-3.11.5 torch-2.1.0 CPU (AMD Ryzen 9 5900X 12-Core Processor)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/classify/train12/weights/best.pt' with input shape (1, 3, 512, 512) BCHW and output shape(s) (1, 10) (2.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.0...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.35...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 0.8s, saved as 'runs/classify/train12/weights/best.onnx' (5.5 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m running 'onnx2tf -i \"runs/classify/train12/weights/best.onnx\" -o \"runs/classify/train12/weights/best_saved_model\" -nuo --non_verbose'\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 6.3s, saved as 'runs/classify/train12/weights/best_saved_model' (13.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.13.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as 'runs/classify/train12/weights/best_saved_model/best_float32.tflite' (5.5 MB)\n",
      "\n",
      "Export complete (7.5s)\n",
      "Results saved to \u001b[1m/home/pepe/dev/upb/topics/ai-topics-2-2023/2.computer_vision_deployment/2.2.training/runs/classify/train12/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=runs/classify/train12/weights/best_saved_model/best_float32.tflite imgsz=512  \n",
      "Validate:        yolo val task=classify model=runs/classify/train12/weights/best_saved_model/best_float32.tflite imgsz=512 data=/home/pepe/dev/upb/topics/cats  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/classify/train12/weights/best_saved_model/best_float32.tflite'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.208 🚀 Python-3.11.5 torch-2.1.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24252MiB)\n",
      "Setup complete ✅ (24 CPUs, 62.7 GB RAM, 921.8/1099.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (24 CPUs, 62.7 GB RAM, 921.8/1099.0 GB disk)\n",
      "\n",
      "Benchmarks complete for best.pt on /home/pepe/dev/upb/topics/cats at imgsz=512 (112.83s)\n",
      "                   Format Status❔  Size (MB)  metrics/accuracy_top1  Inference time (ms/im)\n",
      "0                 PyTorch       ✅        2.8                   0.96                    2.23\n",
      "1             TorchScript       ✅        5.7                   0.96                    1.43\n",
      "2                    ONNX       ✅        2.8                   0.96                   37.09\n",
      "3                OpenVINO       ❌        0.0                    NaN                     NaN\n",
      "4                TensorRT       ✅        3.8                   0.96                    0.28\n",
      "5                  CoreML       ❌        0.0                    NaN                     NaN\n",
      "6   TensorFlow SavedModel       ✅       13.9                   0.96                   15.75\n",
      "7     TensorFlow GraphDef       ✅        5.6                   0.96                   16.66\n",
      "8         TensorFlow Lite       ❌        0.0                    NaN                     NaN\n",
      "9     TensorFlow Edge TPU       ❌        0.0                    NaN                     NaN\n",
      "10          TensorFlow.js       ❌        0.0                    NaN                     NaN\n",
      "11           PaddlePaddle       ❌        0.0                    NaN                     NaN\n",
      "12                   ncnn       ✅        2.8                   0.96                   13.95\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Status❔</th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>metrics/accuracy_top1</th>\n",
       "      <th>Inference time (ms/im)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PyTorch</td>\n",
       "      <td>✅</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TorchScript</td>\n",
       "      <td>✅</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ONNX</td>\n",
       "      <td>✅</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>37.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenVINO</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TensorRT</td>\n",
       "      <td>✅</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CoreML</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TensorFlow SavedModel</td>\n",
       "      <td>✅</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.96</td>\n",
       "      <td>15.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TensorFlow GraphDef</td>\n",
       "      <td>✅</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.96</td>\n",
       "      <td>16.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TensorFlow Lite</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TensorFlow Edge TPU</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TensorFlow.js</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PaddlePaddle</td>\n",
       "      <td>❌</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ncnn</td>\n",
       "      <td>✅</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>13.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Format Status❔  Size (MB)  metrics/accuracy_top1  Inference time (ms/im)\n",
       "0                 PyTorch       ✅        2.8                   0.96                    2.23\n",
       "1             TorchScript       ✅        5.7                   0.96                    1.43\n",
       "2                    ONNX       ✅        2.8                   0.96                   37.09\n",
       "3                OpenVINO       ❌        0.0                    NaN                     NaN\n",
       "4                TensorRT       ✅        3.8                   0.96                    0.28\n",
       "5                  CoreML       ❌        0.0                    NaN                     NaN\n",
       "6   TensorFlow SavedModel       ✅       13.9                   0.96                   15.75\n",
       "7     TensorFlow GraphDef       ✅        5.6                   0.96                   16.66\n",
       "8         TensorFlow Lite       ❌        0.0                    NaN                     NaN\n",
       "9     TensorFlow Edge TPU       ❌        0.0                    NaN                     NaN\n",
       "10          TensorFlow.js       ❌        0.0                    NaN                     NaN\n",
       "11           PaddlePaddle       ❌        0.0                    NaN                     NaN\n",
       "12                   ncnn       ✅        2.8                   0.96                   13.95"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics.utils.benchmarks import benchmark\n",
    "benchmark(model=\"runs/classify/train10/weights/best.pt\", data=\"/home/pepe/dev/upb/topics/cats\", imgsz=image_size, half=True, device=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
