{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Conceptos básicos de Pytorch\n",
    "En este tutorial veremos algunos conceptos importantes para poder comenzar a utilizar pytorch para tareas de deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores\n",
    "Un **tensor** es un arreglo multidimensional con elementos del mismo tipo (dtype). En escencia, un tensor de pytorch es muy similar en comportamiento a un array de numpy con algunas diferencias y funcionalidades agregadas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones básicas\n",
    "Veremos como crear y definir tensores usando pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# crear un tensor de rango 0, un escalar, no contiene ejes\n",
    "simple_tensor = torch.tensor(4)\n",
    "print(simple_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# un tensor de rango 1 es similar a una lista de valores, tiene un eje\n",
    "r1_tensor = torch.tensor([2.0,3.0,4.0,5.0])\n",
    "print(r1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# un tensor de rango 2 es una matriz\n",
    "r2_tensor = torch.tensor([[2.0,3.0,4.0,5.0],[1.0,2.0,0.0,1.0]])\n",
    "print(r2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# un tensor puede tener un numero arbitrario de ejes o dimensiones\n",
    "rank_3_tensor = torch.tensor([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],], dtype=torch.float32)\n",
    "                    \n",
    "print(rank_3_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varias formas de visualizar un tensor de más de 2 dimensiones\n",
    "![tensor](3atensor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# se puede convertir un tensor a un array de numpy de varias maneras:\n",
    "M = np.array(r2_tensor)\n",
    "M2 = r2_tensor.numpy()\n",
    "print(M)\n",
    "print(type(M2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# se pueden realizar operaciones basicas con tensores como adicion, multiplicacion y multiplicacion de matrices\n",
    "a = torch.tensor([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = torch.tensor([[1, 1],\n",
    "                 [1, 1]]) # tambien se puede usar `tf.ones([2,2])`\n",
    "\n",
    "print(torch.add(a, b), \"\\n\")\n",
    "print(torch.multiply(a, b), \"\\n\")\n",
    "print(torch.matmul(a, b), \"\\n\")\n",
    "print('numpy:',np.dot(a.numpy(), b.numpy()))\n",
    "print(a + b, \"\\n\") # element-wise addition\n",
    "print(a * b, \"\\n\") # element-wise multiplication\n",
    "print(a @ b, \"\\n\") # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# se pueden usar tensores en todo tipo de operaciones adicionales\n",
    "c = torch.tensor([[4.0, 5.0], [10.0, 1.0]])\n",
    "\n",
    "# valor maximo\n",
    "print(torch.max(c))\n",
    "# indice del valor maximo\n",
    "print(torch.argmax(c))\n",
    "# calcular la funcion softmax\n",
    "print(torch.nn.functional.softmax(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tienen alguas definiciones importantes (similares a numpy):\n",
    "\n",
    "  - **shape** es el tamaño (numero de elementos) de cada dimension de un tensor.\n",
    "  - **rank** es el numero de dimensiones del tensor, un escalar tiene rank 0, una matriz rank 2\n",
    "  - **axis** o **dimension** es una dimensión en particular de un tensor.\n",
    "  - **size** el numero total de elementos de un tensor, el producto del vector *shape*.\n",
    "  \n",
    "Podemos visualizar para un tensor de rank 4\n",
    "\n",
    "\n",
    "![r4](4atensor.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank_4_tensor = torch.zeros([3, 2, 4, 5])\n",
    "\n",
    "print(\"Tipo de cada elemento:\", rank_4_tensor.dtype)\n",
    "print(\"Numero de dimensiones:\", rank_4_tensor.ndim)\n",
    "print(\"Shape:\", rank_4_tensor.shape)\n",
    "print(\"Elementos en el eje 0 del tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elementos en el ultimo eje del tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Numero total de elementos (3*2*4*5): \", rank_4_tensor.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank_1_tensor = torch.tensor([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
    "# indexado con un escalar\n",
    "print(rank_1_tensor.numpy())\n",
    "print(\"First:\", rank_1_tensor[0].numpy())\n",
    "print(\"Second:\", rank_1_tensor[1].numpy())\n",
    "print(\"Last:\", rank_1_tensor[-1].numpy())\n",
    "# indexado con un slice\n",
    "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
    "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
    "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
    "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
    "print(\"Every other item:\", rank_1_tensor[::2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank_2_tensor = torch.tensor([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=torch.float16)\n",
    "print(rank_2_tensor.numpy())\n",
    "                            \n",
    "# pasando un entero por cada dimension, arroja un escalar\n",
    "print(rank_2_tensor[1, 1].numpy())\n",
    "\n",
    "# Se puede indexar usando combinaciones de escalares y slices\n",
    "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
    "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Skip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ejemplo de un tensor de 3 dimensiones\n",
    "print(rank_3_tensor[:, :, 4].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3slice](3rslice.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# los tensores son mutables\n",
    "mi_variable = torch.tensor([1, 2, 3])\n",
    "print(mi_variable + 1)\n",
    "v = torch.tensor(0.0)\n",
    "w = v + 1 \n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo automático de gradientes\n",
    "\n",
    "Para poder usar la capacidad de diferenciación automática de pytorch, se necesita recordar todas las operaciones que han ocurrido y el orden de ocurrencia durante el *forward pass*. Luego, durante el *backward pass*, pytorch puede recorrer la lista de operaciones y calcular las gradientes.\n",
    "\n",
    "### autograd\n",
    "Pytorch provee la API de **torch.autograd** para la diferenciación automática y poder calcular las gradientes de un grafo de cómputo con respecto a ciertas variables de entrada. Pytorch \"recuerda\" todas las operaciones ejecutadas dentro un contexto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "# y = x ^ 2\n",
    "y = x ** 2\n",
    "# dy = 2x\n",
    "y.backward()\n",
    "dy_dx = x.grad\n",
    "print(y.grad_fn)\n",
    "print(dy_dx.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(7.0, requires_grad=True)\n",
    "y = x + 4\n",
    "z = y ** 2 - 6\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([3.0, 3.0], requires_grad=True)\n",
    "\n",
    "z = torch.multiply(x, x)\n",
    "\n",
    "print(z)\n",
    "\n",
    "z.backward(torch.tensor([1, 1]))\n",
    "# Find derivative of z with respect to the original input tensor x\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien se puede solicitar gradientes de la salida con respecto a valores intermedios calculados durante una \"grabación\" de un contexto tf.GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([3.0, 3.0], requires_grad=True)\n",
    "y = torch.multiply(x, x)\n",
    "z = torch.multiply(y, y)\n",
    "z.backward(torch.tensor([1, 1]))\n",
    "# dz_dx = 2 * y, donde: y = x ^ 2\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion lineal en pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import random\n",
    "# X y y ya son arrays de numpy\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "m = X.shape[0]\n",
    "unos = np.ones((m, 1))\n",
    "X = np.append(unos, X, axis=1)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62eb3e910e44ea0e9978ea29c6f3fc7540fb99bfa181faf1a80d42ed442aa249"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('unifranz': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
