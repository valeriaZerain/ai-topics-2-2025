{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV\n",
    "\n",
    "OpenCV es un conjunto de herramientas open source para aplicaciones de visión artificial. Contiene distintas utilidades y algoritmos implementados y optimizados para realizar operaciones comunes en pipelines de visión artificial:\n",
    "\n",
    " - Herramientas de lectura y escritura de imágenes y video.\n",
    " - Algoritmos optimizados (implementación en C++) accesibles.\n",
    " - Utilidades para creación de GUI.\n",
    " - Extensibilidad con otras herramientas y librerías.\n",
    " - Ampliamente usado en la industria y con una gran comunidad.\n",
    " - Documentación y material extensivo disponible en internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones Básicas\n",
    "OpenCV usa arrays de Numpy para manipular imágenes en memoria. Los arrays de numpy son estructuras optimizadas para operaciones con arreglos multidimensionales similar a lo que se tiene en el entorno de Matlab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceder y modificar pixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "uint8\n",
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# para cargar una imagen en memoria se usa la funcion imread()\n",
    "img = cv2.imread(\"lenna.png\")\n",
    "print(type(img))\n",
    "print(img.dtype)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acceder al valor de un pixel se usa la posicion en cada dimension `img[fila, col]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[100, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV usa por defecto una representación BGR, para ver el canal azul, podemos acceder al primer elemento del pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[89, 100, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para modificar el valor del pixel simplemente se puede asignar un nuevo valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[100, 100] = [255, 255, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[97:103, 97:103, 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar una imagen en un notebook de jupyter\n",
    "Para visualizar una imagen de OpenCV en un notebook de jupyter debemos usar la librería `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir a rgb\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# print(img[98:102, 98:102, 0])\n",
    "# print(img_hsv[98:102, 98:102, 0])\n",
    "plt.imshow(img_hsv, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando una funcion\n",
    "\n",
    "def display(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI\n",
    "La Región de Interés o ROI (Region of Interest) puede ser definida usando el indexado de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#           filas  , columnas\n",
    "display(img[200:380, 210:350])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones sobre imágenes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending\n",
    "Se suman dos imágenes con distintos niveles de ponderación de manera que se pueda obtener una transparencia, se opera de acuerdo a la siguiente fórmula:\n",
    "\n",
    "$$g(x) = (1 - \\alpha)f_0(x) + \\alpha f_1(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"lenna.png\")\n",
    "img2 = cv2.imread(\"opencv.png\")\n",
    "print(img1.shape, img2.shape)\n",
    "\n",
    "display(cv2.addWeighted(img1, 0.8, img2, 0.2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambio de espacios de color\n",
    "Existen más de 150 operaciones para conversiones de espacios de color en OpenCV. Usaremos una vez más la función `cvtColor()` \n",
    "\n",
    "Para la conversión de BGR a HSV, es importante tomar en cuenta que los rangos para HSV son los siguientes:\n",
    "\n",
    "  - hue: [0, 179]\n",
    "  - saturation: [0, 255]\n",
    "  - value: [0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hsv = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "print(img1[100, 100], img_hsv[100, 100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "print(img1.shape, img_gray.shape)\n",
    "display(img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filas = 300\n",
    "n_cols = 700\n",
    "# dimensiones de salida de forma explicita\n",
    "                        #     x    , y\n",
    "img_long = cv2.resize(img1, (n_cols, n_filas), interpolation=cv2.INTER_CUBIC)\n",
    "display(img_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_filas = 1.9\n",
    "factor_cols = 0.4\n",
    "\n",
    "display(cv2.resize(img1, None, fy=factor_filas, fx=factor_cols, interpolation=cv2.INTER_CUBIC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotación\n",
    "La rotación por un ángulo $\\theta$ se puede lograr en base a la siguiente transformación:\n",
    "\n",
    "$$ M = \\begin{bmatrix}cos(\\theta) & -sin(\\theta)\\\\ sin(\\theta) & cos(\\theta)\\end{bmatrix}$$\n",
    "\n",
    "En OpenCV se puede usar la funcion `getRotationMatrix2D` para obtener una matriz de tranformación afín que represente la rotación deseada, y luego aplicar esta transformación a la imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensiones = (400, 400, 3)\n",
    "filas, columnas, _ = dimensiones\n",
    "# columnas = dimensiones[1]\n",
    "# canales = dimensiones[2]\n",
    "\n",
    "print(f\"Dim: {dimensiones} -> filas: {filas}, cols: {columnas}, canales: {canales}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener solamente el canal B\n",
    "img3 = img1#[:,:,0]\n",
    "\n",
    "filas, cols, _ = img3.shape\n",
    "print(img3.shape)\n",
    "theta = -25\n",
    "\n",
    "# #                           (centro x      , centro y        , theta, escala)\n",
    "M = cv2.getRotationMatrix2D((0, 0), theta, 1)\n",
    "print(M)\n",
    "# #                     (img, matriz, size) \n",
    "display(cv2.warpAffine(img3, M, (cols, filas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Superponer la imagen de la flecha roja del archivo `flecha.png` con un tamaño de 100x100 pixeles sobre la imagen de `lenna.png` en la **esquina superior derecha** rotado en un ángulo de **135 grados*, como se puede observar en el ejemplo:\n",
    "\n",
    "![result](output.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-topics-2-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
